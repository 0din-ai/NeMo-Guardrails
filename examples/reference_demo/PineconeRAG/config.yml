instructions:
  - type: general
    content: |
      Below is a conversation between a bot and a user where the user asks the bot questions and the bot answers the questions based on documents the bot has access to. The user can ask as many questions to the bot. Any question that does not pertain to the data the bot has access to should not be answered.

sample_conversation: |
  user "Hello"
      express greeting
  bot express greeting
      "Hello"
  user "What does Nvidia do?"
      ask question 
  bot retrieve relevant chunks
    "Nvidia is a technology company"
  user "Who is the CEO of Nvidia?"
      ask question
  bot retrieve relevant chunks
      "Jensen Huang is the CEO of Nvidia"
  

models:
  - type: main
    engine: openai
    model: text-davinci-003

  - type: embeddings
    engine: openai
    model: text-embedding-ada-002

#if you dont want to call the search backend to index the data in the kb folder, dont add these here
# Use the simple embedding search provider for the core logic.
#core:
#  embedding_search_provider:
#    name: simple

# And for the knowledge base.
#knowledge_base:
#  embedding_search_provider:
#    name: simple